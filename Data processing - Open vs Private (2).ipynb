{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d07d6df-8e3b-4838-b114-b52f729704c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenyuli/OpenScience/Code/OpenVsPrivateDatasets/Data processing - Open vs Private (2).ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenyuli/OpenScience/Code/OpenVsPrivateDatasets/Data%20processing%20-%20Open%20vs%20Private%20%282%29.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# import dimcli\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenyuli/OpenScience/Code/OpenVsPrivateDatasets/Data%20processing%20-%20Open%20vs%20Private%20%282%29.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chenyuli/OpenScience/Code/OpenVsPrivateDatasets/Data%20processing%20-%20Open%20vs%20Private%20%282%29.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py3/lib/python3.11/site-packages/pandas/__init__.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig_init\u001b[39;00m  \u001b[39m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     \u001b[39m# dtype\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     ArrowDtype,\n\u001b[1;32m     49\u001b[0m     Int8Dtype,\n\u001b[1;32m     50\u001b[0m     Int16Dtype,\n\u001b[1;32m     51\u001b[0m     Int32Dtype,\n\u001b[1;32m     52\u001b[0m     Int64Dtype,\n\u001b[1;32m     53\u001b[0m     UInt8Dtype,\n\u001b[1;32m     54\u001b[0m     UInt16Dtype,\n\u001b[1;32m     55\u001b[0m     UInt32Dtype,\n\u001b[1;32m     56\u001b[0m     UInt64Dtype,\n\u001b[1;32m     57\u001b[0m     Float32Dtype,\n\u001b[1;32m     58\u001b[0m     Float64Dtype,\n\u001b[1;32m     59\u001b[0m     CategoricalDtype,\n\u001b[1;32m     60\u001b[0m     PeriodDtype,\n\u001b[1;32m     61\u001b[0m     IntervalDtype,\n\u001b[1;32m     62\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     63\u001b[0m     StringDtype,\n\u001b[1;32m     64\u001b[0m     BooleanDtype,\n\u001b[1;32m     65\u001b[0m     \u001b[39m# missing\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     NA,\n\u001b[1;32m     67\u001b[0m     isna,\n\u001b[1;32m     68\u001b[0m     isnull,\n\u001b[1;32m     69\u001b[0m     notna,\n\u001b[1;32m     70\u001b[0m     notnull,\n\u001b[1;32m     71\u001b[0m     \u001b[39m# indexes\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     Index,\n\u001b[1;32m     73\u001b[0m     CategoricalIndex,\n\u001b[1;32m     74\u001b[0m     RangeIndex,\n\u001b[1;32m     75\u001b[0m     MultiIndex,\n\u001b[1;32m     76\u001b[0m     IntervalIndex,\n\u001b[1;32m     77\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     78\u001b[0m     DatetimeIndex,\n\u001b[1;32m     79\u001b[0m     PeriodIndex,\n\u001b[1;32m     80\u001b[0m     IndexSlice,\n\u001b[1;32m     81\u001b[0m     \u001b[39m# tseries\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     NaT,\n\u001b[1;32m     83\u001b[0m     Period,\n\u001b[1;32m     84\u001b[0m     period_range,\n\u001b[1;32m     85\u001b[0m     Timedelta,\n\u001b[1;32m     86\u001b[0m     timedelta_range,\n\u001b[1;32m     87\u001b[0m     Timestamp,\n\u001b[1;32m     88\u001b[0m     date_range,\n\u001b[1;32m     89\u001b[0m     bdate_range,\n\u001b[1;32m     90\u001b[0m     Interval,\n\u001b[1;32m     91\u001b[0m     interval_range,\n\u001b[1;32m     92\u001b[0m     DateOffset,\n\u001b[1;32m     93\u001b[0m     \u001b[39m# conversion\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     to_numeric,\n\u001b[1;32m     95\u001b[0m     to_datetime,\n\u001b[1;32m     96\u001b[0m     to_timedelta,\n\u001b[1;32m     97\u001b[0m     \u001b[39m# misc\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     Flags,\n\u001b[1;32m     99\u001b[0m     Grouper,\n\u001b[1;32m    100\u001b[0m     factorize,\n\u001b[1;32m    101\u001b[0m     unique,\n\u001b[1;32m    102\u001b[0m     value_counts,\n\u001b[1;32m    103\u001b[0m     NamedAgg,\n\u001b[1;32m    104\u001b[0m     array,\n\u001b[1;32m    105\u001b[0m     Categorical,\n\u001b[1;32m    106\u001b[0m     set_eng_float_format,\n\u001b[1;32m    107\u001b[0m     Series,\n\u001b[1;32m    108\u001b[0m     DataFrame,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    113\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtseries\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m~/anaconda3/envs/py3/lib/python3.11/site-packages/pandas/core/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     NaT,\n\u001b[1;32m      3\u001b[0m     Period,\n\u001b[1;32m      4\u001b[0m     Timedelta,\n\u001b[1;32m      5\u001b[0m     Timestamp,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmissing\u001b[39;00m \u001b[39mimport\u001b[39;00m NA\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ArrowDtype,\n\u001b[1;32m     11\u001b[0m     CategoricalDtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     PeriodDtype,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py3/lib/python3.11/site-packages/pandas/_libs/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas_parser\u001b[39;00m  \u001b[39m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas_datetime\u001b[39;00m  \u001b[39m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterval\u001b[39;00m \u001b[39mimport\u001b[39;00m Interval\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     NaT,\n\u001b[1;32m     21\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     iNaT,\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mmissing.pyx:42\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# import dimcli\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076fed77-0c47-40c2-8eeb-29a0ba40d12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mDimcli - Dimensions API Client (v1.0.3)\u001b[0m\n",
      "\u001b[2mConnected to: <https://app.dimensions.ai/api/dsl> - DSL v2.8\u001b[0m\n",
      "\u001b[2mMethod: manual login\u001b[0m\n",
      "====\n",
      "Heads up! The latest Dimcli version is  1.1\n",
      "You have installed:  1.0.3\n",
      "====\n",
      "Please upgrade: `pip install dimcli -U`\n"
     ]
    }
   ],
   "source": [
    "dimcli.login(\n",
    "    key=\"\", endpoint=\"https://app.dimensions.ai\"\n",
    ")\n",
    "dsl = dimcli.Dsl()\n",
    "\n",
    "get_new_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294fdad0-edad-4f3b-87e3-a37dbcf69ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(ser: pd.Series):\n",
    "    return np.array_split(ser, ser.shape[0] / 400)\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    if get_new_data:\n",
    "        control = pd.read_csv(\"control-pmid.csv\")\n",
    "        \"\"\"Query:\n",
    "        https://pubmed.ncbi.nlm.nih.gov/?term=%28%28%22machine+learning%22%5BMajr%5D+OR+%28%22machine%22%5Bti%5D+AND+%22learning%22%5Bti%5D%29+OR+%22machine+learning%22%5Bti%5D+OR+%22AI%22%5Bti%5D+OR+%22Artificial+Intelligence%22%5Bti%5D+OR+%22artificially+intelligent%22%5Bti%5D+OR+%22Artificial+Intelligence%22%5BMeSH%5D+OR+%22Algorithms%22%5BMeSH%5D+OR+%22algorithm*%22%5Bti%5D+OR+%22deep+learning%22%5Bti%5D+OR+%22computer+vision%22%5Bti%5D+OR+%22natural+language+processing%22%5Bti%5D+OR+%22neural+network*%22%5Bti%5D+OR+%22neural+networks%2C+computer%22%5BMeSH%5D+OR+%22intelligent+machine*%22%5Bti%5D%29+AND+%28exp+%22Intensive+Care+Units%22%2F+OR+exp+%22Critical+Care%22%2F+OR+%28ICU+OR+IC+OR+%28%28intensive+OR+critical%29+ADJ3+%28care+OR+therapy+OR+unit*+OR+patient*+OR+department%5C*%29%29%29%29%29&filter=years.2010-2023\n",
    "        \"\"\"\n",
    "        df_pubs_control = pd.DataFrame()\n",
    "        df_auths_control = pd.DataFrame()\n",
    "        df_affils_control = pd.DataFrame()\n",
    "\n",
    "        for pmid_list in get_split(control.PMID):\n",
    "            query = fr\"\"\"search publications where pmid in {list(pmid_list)} and year in [2010:2022]\n",
    "            return publications[basics+abstract+authors_count+doi+concepts_scores+times_cited+mesh_terms\n",
    "            +journal+editors+field_citation_ratio+funder_countries+funders+open_access\n",
    "            +relative_citation_ratio+publisher+pmid+supporting_grant_ids+research_org_cities+pmid\n",
    "            +research_org_countries+research_org_country_names+research_org_names+research_org_state_codes\n",
    "            +research_org_state_names+research_orgs+researchers+category_bra+category_for+category_hra+category_hrcs_hc+\n",
    "            category_hrcs_rac+category_icrp_cso+category_icrp_ct+category_rcdc+category_sdg+category_uoa]\"\"\"\n",
    "            data = dsl.query_iterative(query)\n",
    "            df_pubs_control = pd.concat([df_pubs_control, data.as_dataframe()])\n",
    "            df_auths_control = pd.concat(\n",
    "                [df_auths_control, data.as_dataframe_authors()]\n",
    "            )\n",
    "            df_affils_control = pd.concat(\n",
    "                [df_affils_control, data.as_dataframe_authors_affiliations()]\n",
    "            )\n",
    "\n",
    "        df_pubs_control.to_csv(\"control_group_pubs.csv\")\n",
    "        df_auths_control.to_csv(\"control_group_auths.csv\")\n",
    "        df_affils_control.to_csv(\"control_group_affils.csv\")\n",
    "\n",
    "        compare_query = fr\"\"\"search publications where year in [2010:2022] for \"\\\"datamed org display item php\\\" OR \\\"physionet mimic ii database\\\" \n",
    "        OR \\\"mimic iii medical information mart for intensive care\\\" OR\n",
    "        \\\"10.13026 s6n6 xd98\\\" OR \\\"mimic iv\\\" OR \\\"physionet org content mimiciv\\\" OR\n",
    "        \\\"eicu crd\\\" OR \\\"mimic cxr\\\"\" return publications[basics+abstract+authors_count+doi+concepts_scores+times_cited\n",
    "            +mesh_terms+journal+editors+field_citation_ratio+funder_countries+funders+open_access\n",
    "            +relative_citation_ratio+publisher+pmid+supporting_grant_ids+research_org_cities+pmid\n",
    "            +research_org_countries+research_org_country_names+research_org_names+research_org_state_codes\n",
    "            +research_org_state_names+research_orgs+researchers+category_bra+category_for+category_hra+category_hrcs_hc+\n",
    "            category_hrcs_rac+category_icrp_cso+category_icrp_ct+category_rcdc+category_sdg+category_uoa]\"\"\"\n",
    "        compare = dsl.query_iterative(compare_query)\n",
    "\n",
    "        df_pubs_compare = compare.as_dataframe()\n",
    "        df_auths_compare = compare.as_dataframe_authors()\n",
    "        df_affils_compare = compare.as_dataframe_authors_affiliations()\n",
    "\n",
    "        df_pubs_compare.to_csv(\"mimic_pubs.csv\")\n",
    "        df_auths_compare.to_csv(\"mimic_auths.csv\")\n",
    "        df_affils_compare.to_csv(\"mimic_affils.csv\")\n",
    "\n",
    "    else:\n",
    "        df_pubs_compare = pd.read_csv(\"MIMIC Files/mimic_pubs (1).csv\")\n",
    "        df_auths_compare = pd.read_csv(\"MIMIC Files/mimic_auths.csv\")\n",
    "        df_affils_compare = pd.read_csv(\"MIMIC Files/mimic_affils.csv\")\n",
    "\n",
    "        df_pubs_control = pd.read_csv(\"MIMIC Files/control_group_pubs.csv\")\n",
    "        df_auths_control = pd.read_csv(\"MIMIC Files/control_group_auths.csv\")\n",
    "        df_affils_control = pd.read_csv(\"MIMIC Files/control_group_affils (1).csv\")\n",
    "\n",
    "    return (\n",
    "        df_pubs_compare,\n",
    "        df_auths_compare,\n",
    "        df_affils_compare,\n",
    "        df_pubs_control,\n",
    "        df_auths_control,\n",
    "        df_affils_control,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b3a94e-bbcb-40e9-b27d-09072f1aff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_pubs_compare,\n",
    "    df_auths_compare,\n",
    "    df_affils_compare,\n",
    "    df_pubs_control,\n",
    "    df_auths_control,\n",
    "    df_affils_control,\n",
    ") = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f2c6d7-0dbf-42e2-96fd-1027a01b3d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare\n",
      "Papers w/ Missing Publications:   0\n",
      "Papers w/ Missing Authors:        110\n",
      "Papers w/ Missing Affiliations:   635\n",
      "\n",
      "Control\n",
      "Papers w/ Missing Publications:   0\n",
      "Papers w/ Missing Authors:        2\n",
      "Papers w/ Missing Affiliations:   35\n"
     ]
    }
   ],
   "source": [
    "def get_missingness(df_pubs, df_auths, df_affils):\n",
    "    df_completeness = pd.DataFrame()\n",
    "    df_completeness[\"id\"] = df_pubs[\"id\"]\n",
    "\n",
    "    df_completeness[\"Publications\"] = True\n",
    "    df_completeness[\"Authors\"] = df_pubs.id.isin(df_auths.pub_id)\n",
    "    df_completeness[\"Affiliations\"] = df_pubs.id.isin(df_affils.pub_id)\n",
    "\n",
    "    df_completeness.head()\n",
    "    print(f\"Papers w/ Missing Publications:   0\")\n",
    "    print(\n",
    "        f\"Papers w/ Missing Authors:        {df_completeness.Authors.value_counts()[False]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Papers w/ Missing Affiliations:   {df_completeness.Affiliations.value_counts()[False]}\"\n",
    "    )\n",
    "\n",
    "    return None  # df_completeness\n",
    "\n",
    "\n",
    "print(\"Compare\")\n",
    "get_missingness(df_pubs_compare, df_auths_compare, df_affils_compare)\n",
    "print()\n",
    "print(\"Control\")\n",
    "get_missingness(df_pubs_control, df_auths_control, df_affils_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17a57ae5-ca82-43ee-bb8e-f9f5eaa976eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender_dictionary = pd.read_csv(\"_name_genderize_output (1).csv\")\n",
    "df_gender_dictionary.drop_duplicates(\"ga_first_name\", inplace=True)\n",
    "df_gender_dictionary.set_index(\"ga_first_name\", inplace=True)\n",
    "\n",
    "\n",
    "CountryClass = pd.read_excel(\"CountryClassWordBank (1).xlsx\")\n",
    "CountryClass_2 = CountryClass.copy()\n",
    "CountryClass_2.set_index(\"Code\", inplace=True)\n",
    "\n",
    "import re\n",
    "import typing\n",
    "from ast import literal_eval\n",
    "from typing import Iterable\n",
    "\n",
    "import dataframe_image as dfi\n",
    "import dimcli\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "missing_codes = []\n",
    "\n",
    "\n",
    "gender_dict = dict(zip(df_gender_dictionary.index, df_gender_dictionary.ga_gender))\n",
    "country_dict = dict(zip(CountryClass_2.index, CountryClass_2[\"Income group\"]))\n",
    "gender_map = {\"male\": 0, \"female\": 1, \"unknown\": np.nan}\n",
    "income_map = {\n",
    "    \"High income\": 4,\n",
    "    \"Upper middle income\": 3,\n",
    "    \"Lower middle income\": 2,\n",
    "    \"Low income\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "def get_gender(name):\n",
    "    if pd.isna(name):\n",
    "        return np.nan\n",
    "    name = name.strip()\n",
    "    name = name.split(sep=\" \")[0]\n",
    "    if name in gender_dict:\n",
    "        return gender_dict[name]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_gender_ints(gender):\n",
    "    if gender in gender_map:\n",
    "        return gender_map[gender]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_country_income(country_code):\n",
    "    if pd.isna(country_code):\n",
    "        return np.nan\n",
    "    country_ISO3 = pycountry.countries.get(alpha_2=country_code)\n",
    "    if country_ISO3 is None:\n",
    "        missing_codes.append(country_code)\n",
    "        return np.nan\n",
    "    elif country_ISO3.alpha_3 in country_dict:\n",
    "        return country_dict[country_ISO3.alpha_3]\n",
    "    else:\n",
    "        missing_codes.append(country_code)\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def map_country_income(income_group):\n",
    "    if income_group in income_map:\n",
    "        return income_map[income_group]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_pub_year(pub_id, df_pubs):\n",
    "    return df_pubs.at[pub_id, \"year\"]\n",
    "\n",
    "\n",
    "def categorize_author_counts(num_authors):\n",
    "    if pd.isna(num_authors) or num_authors == 0:\n",
    "        return np.nan\n",
    "    if num_authors == 1:\n",
    "        return \"1\"\n",
    "    if num_authors == 2:\n",
    "        return \"2\"\n",
    "    if num_authors >= 3 and num_authors <= 5:\n",
    "        return \"3-5\"\n",
    "    if num_authors >= 6:\n",
    "        return \"6+\"\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def pipeline(list_of_dataframes: list):\n",
    "    df_pubs, df_auths, df_affils = list_of_dataframes\n",
    "    df_pubs_copy = df_pubs.copy()\n",
    "    df_pubs_copy.set_index(\"id\", inplace=True)\n",
    "\n",
    "    df_auths[\"year\"] = df_auths[\"pub_id\"].apply(\n",
    "        lambda pid: get_pub_year(pid, df_pubs_copy)\n",
    "    )\n",
    "    df_affils[\"year\"] = df_affils[\"pub_id\"].apply(\n",
    "        lambda pid: get_pub_year(pid, df_pubs_copy)\n",
    "    )\n",
    "\n",
    "    df_auths[\"first_name\"] = df_auths[\"first_name\"].str.title()\n",
    "    df_affils[\"first_name\"] = df_affils[\"first_name\"].str.title()\n",
    "\n",
    "    df_auths[\"gender\"] = df_auths[\"first_name\"].map(get_gender)\n",
    "    df_affils[\"gender\"] = df_affils[\"first_name\"].map(get_gender)\n",
    "\n",
    "    df_auths[\"gender_ints\"] = df_auths[\"gender\"].map(get_gender_ints)\n",
    "    df_affils[\"gender_ints\"] = df_affils[\"gender\"].map(get_gender_ints)\n",
    "\n",
    "    df_pubs[\"author_count_categories\"] = df_pubs[\"authors_count\"].apply(\n",
    "        categorize_author_counts\n",
    "    )\n",
    "\n",
    "    lfirstnames = dict.fromkeys(df_pubs.id, np.nan)\n",
    "    lgenders = dict.fromkeys(df_pubs.id, np.nan)\n",
    "    lpctfemale = dict.fromkeys(df_pubs.id, np.nan)\n",
    "    lffirst = dict.fromkeys(df_pubs.id, np.nan)\n",
    "    lflast = dict.fromkeys(df_pubs.id, np.nan)\n",
    "    lnfemale = dict.fromkeys(df_pubs.id, np.nan)\n",
    "    lnmale = dict.fromkeys(df_pubs.id, np.nan)\n",
    "    lnnan = dict.fromkeys(df_pubs.id, np.nan)\n",
    "\n",
    "    for pub_id, df_info in df_auths.groupby(\"pub_id\"):\n",
    "        lfirstnames[pub_id] = df_info[\"first_name\"]\n",
    "        lgenders[pub_id] = df_info[\"gender_ints\"]\n",
    "\n",
    "        genders = df_info[\"gender_ints\"]\n",
    "\n",
    "        lffirst[pub_id] = genders.iloc[0]\n",
    "        lflast[pub_id] = genders.iloc[-1]\n",
    "\n",
    "        num_female = (genders == 1).sum()\n",
    "        num_male = (genders == 0).sum()\n",
    "        num_missing = genders.isna().sum()\n",
    "        lnfemale[pub_id] = num_female  \n",
    "        lnmale[pub_id] = num_male \n",
    "        lnnan[pub_id] = num_missing  \n",
    "        total = num_male + num_female\n",
    "        if total == 0:\n",
    "            lpctfemale[pub_id] = np.nan\n",
    "        else:\n",
    "            lpctfemale[pub_id] = num_female / total\n",
    "\n",
    "    df_pubs[\"first_names\"] = lfirstnames.values()\n",
    "    df_pubs[\"genders\"] = lgenders.values()\n",
    "    df_pubs[\"num_female\"] = lnfemale.values()\n",
    "    df_pubs[\"num_male\"] = lnmale.values()\n",
    "    df_pubs[\"num_na\"] = lnnan.values()\n",
    "    df_pubs[\"pct_female_real\"] = lpctfemale.values()\n",
    "    df_pubs[\"female_first\"] = lffirst.values()\n",
    "    df_pubs[\"female_last\"] = lflast.values()\n",
    "\n",
    "    cols = [\"num_female\", \"num_male\", \"num_na\"]\n",
    "    total = df_pubs[cols[0]] + df_pubs[cols[1]] + df_pubs[cols[2]]\n",
    "    df_pubs[\"pct_female_pessimistic\"] = df_pubs[cols[0]] / total\n",
    "    df_pubs[\"pct_female_optimistic\"] = (df_pubs[cols[0]] + df_pubs[cols[2]]) / total\n",
    "    df_pubs[\"female_first_pessimistic\"] = df_pubs[\"female_first\"].apply(\n",
    "        lambda x: 0 if pd.isna(x) else x\n",
    "    )\n",
    "    df_pubs[\"female_first_optimistic\"] = df_pubs[\"female_first\"].apply(\n",
    "        lambda x: 1 if pd.isna(x) else x\n",
    "    )\n",
    "    df_pubs[\"female_last_pessimistic\"] = df_pubs[\"female_last\"].apply(\n",
    "        lambda x: 0 if pd.isna(x) else x\n",
    "    )\n",
    "    df_pubs[\"female_last_optimistic\"] = df_pubs[\"female_last\"].apply(\n",
    "        lambda x: 1 if pd.isna(x) else x\n",
    "    )\n",
    "\n",
    "    df_affils[\"income_class\"] = df_affils[\"aff_country_code\"].apply(get_country_income)\n",
    "    df_affils[\"income_class_num\"] = df_affils[\"income_class\"].map(map_country_income)\n",
    "\n",
    "    return [df_pubs, df_auths, df_affils]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0d0c328-0404-4cb1-a1f0-6a41ce27a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pubs_compare, df_auths_compare, df_affils_compare = pipeline(\n",
    "    [df_pubs_compare, df_auths_compare, df_affils_compare]\n",
    ")\n",
    "\n",
    "df_pubs_control, df_auths_control, df_affils_control = pipeline(\n",
    "    [df_pubs_control, df_auths_control, df_affils_control]\n",
    ")\n",
    "\n",
    "df_pubs_control = df_pubs_control[~df_pubs_control.id.isin(df_pubs_compare.id)]\n",
    "df_auths_control = df_auths_control[~df_auths_control.pub_id.isin(df_pubs_compare.id)]\n",
    "df_affils_control = df_affils_control[\n",
    "    ~df_affils_control.pub_id.isin(df_pubs_compare.id)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7c95f-0d4d-459d-961e-c0f6fd20ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pubs_control.to_csv(\"control_group_pubs.csv\")\n",
    "df_auths_control.to_csv(\"control_group_auths.csv\")\n",
    "df_affils_control.to_csv(\"control_group_affils.csv\")\n",
    "df_pubs_compare.to_csv(\"mimic_pubs.csv\")\n",
    "df_auths_compare.to_csv(\"mimic_auths.csv\")\n",
    "df_affils_compare.to_csv(\"mimic_affils.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0792c621-e2f2-44c5-8c38-e7b134a39576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare group papers: 2307. Pct: 0.4420387047327074\n",
      "Control group papers: 2912. Pct: 0.5579612952672925\n",
      "Total:                5219\n"
     ]
    }
   ],
   "source": [
    "num_compare = df_pubs_compare.shape[0]\n",
    "num_control = df_pubs_control.shape[0]\n",
    "num_total = num_compare + num_control\n",
    "\n",
    "print(f\"Compare group papers: {num_compare}. Pct: {num_compare / num_total}\")\n",
    "print(f\"Control group papers: {num_control}. Pct: {num_control / num_total}\")\n",
    "print(f\"Total:                {num_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "869d3b13-e3a8-4169-b943-45716d42a9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare group authors: 13879. Pct: 0.40324830030797837\n",
      "Control group authors: 20539. Pct: 0.5967516996920216\n",
      "Total:                 34418\n"
     ]
    }
   ],
   "source": [
    "num_compare_auths = df_auths_compare.shape[0]\n",
    "num_control_auths = df_auths_control.shape[0]\n",
    "num_total_auths = num_compare_auths + num_control_auths\n",
    "\n",
    "print(\n",
    "    f\"Compare group authors: {num_compare_auths}. Pct: {num_compare_auths / num_total_auths}\"\n",
    ")\n",
    "print(\n",
    "    f\"Control group authors: {num_control_auths}. Pct: {num_control_auths / num_total_auths}\"\n",
    ")\n",
    "print(f\"Total:                 {num_total_auths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce328c0d-b41d-4a62-8e3a-f1939b170e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare group authors: 6766. Pct: 0.19658318321808357\n",
      "Control group authors: 14821. Pct: 0.4306177000406764\n",
      "Total:                21587\n"
     ]
    }
   ],
   "source": [
    "num_unique_auths_compare = df_auths_compare.researcher_id.nunique()\n",
    "num_unique_auths_control = df_auths_control.researcher_id.nunique()\n",
    "num_total_unique = num_unique_auths_compare + num_unique_auths_control\n",
    "\n",
    "print(\n",
    "    f\"Compare group authors: {num_unique_auths_compare}. Pct: {num_unique_auths_compare / num_total_auths}\"\n",
    ")\n",
    "print(\n",
    "    f\"Control group authors: {num_unique_auths_control}. Pct: {num_unique_auths_control / num_total_auths}\"\n",
    ")\n",
    "print(f\"Total:                {num_total_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13cecd62-e903-46b6-ba1b-d98fb24277eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct_female_real\n",
      "\n",
      "Compare:\n",
      "count    1426.000000\n",
      "mean        0.261378\n",
      "std         0.230498\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.250000\n",
      "75%         0.400000\n",
      "max         1.000000\n",
      "Name: pct_female_real, dtype: float64\n",
      "\n",
      "Control:\n",
      "count    1823.000000\n",
      "mean        0.290255\n",
      "std         0.252795\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.250000\n",
      "75%         0.500000\n",
      "max         1.000000\n",
      "Name: pct_female_real, dtype: float64\n",
      "\n",
      "female_first\n",
      "\n",
      "Compare:\n",
      "count    1426.000000\n",
      "mean        0.281206\n",
      "std         0.449746\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: female_first, dtype: float64\n",
      "\n",
      "Control:\n",
      "count    1823.000000\n",
      "mean        0.309380\n",
      "std         0.462365\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: female_first, dtype: float64\n",
      "\n",
      "female_last\n",
      "\n",
      "Compare:\n",
      "count    1426.000000\n",
      "mean        0.235624\n",
      "std         0.424537\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n",
      "Name: female_last, dtype: float64\n",
      "\n",
      "Control:\n",
      "count    1823.000000\n",
      "mean        0.216676\n",
      "std         0.412093\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n",
      "Name: female_last, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process(df_pubs, df_auths, df_affils):\n",
    "    # Get rid of papers with missing genders\n",
    "    pubs = df_pubs[df_pubs.num_na == 0]\n",
    "    auths = df_auths[df_auths.pub_id.isin(pubs.id)]\n",
    "    affils = df_affils[df_affils.pub_id.isin(pubs.id)]\n",
    "    return pubs, auths, affils\n",
    "\n",
    "\n",
    "def print_col(col):\n",
    "    print(col)\n",
    "    print()\n",
    "    print(\"Compare:\")\n",
    "    print(df_pubs_compare[col].describe())\n",
    "    print()\n",
    "    print(\"Control:\")\n",
    "    print(df_pubs_control[col].describe())\n",
    "    print()\n",
    "\n",
    "\n",
    "df_pubs_compare, df_auths_compare, df_affils_compare = process(\n",
    "    df_pubs_compare, df_auths_compare, df_affils_compare\n",
    ")\n",
    "\n",
    "df_pubs_control, df_auths_control, df_affils_control = process(\n",
    "    df_pubs_control, df_auths_control, df_affils_control\n",
    ")\n",
    "\n",
    "print_col(\"pct_female_real\")\n",
    "print_col(\"female_first\")\n",
    "print_col(\"female_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c9c3d90-2aab-4836-ae34-6e4679f64103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare group:\n",
      "Any female author: 1024  /  0.7180925666199158\n",
      "No female authors: 402   /  0.28190743338008417\n",
      "Total:  1426\n",
      "\n",
      "Control group:\n",
      "Any female author: 1330  /  0.7295666483817883\n",
      "No female authors: 493   /  0.27043335161821175\n",
      "Total:  1823\n"
     ]
    }
   ],
   "source": [
    "def get_female_any(df_auths):\n",
    "    atleast_one = (\n",
    "        df_auths.groupby(\"pub_id\")[\"gender_ints\"].any().value_counts()[True]\n",
    "    )\n",
    "    none = df_auths.groupby(\"pub_id\")[\"gender_ints\"].any().value_counts()[False]\n",
    "    total = df_auths[\"pub_id\"].nunique()\n",
    "\n",
    "    print(f\"Any female author: {atleast_one}  /  {atleast_one / total}\")\n",
    "    print(f\"No female authors: {none}   /  {none / total}\")\n",
    "    print(f\"Total:  {total}\")\n",
    "\n",
    "\n",
    "print(\"Compare group:\")\n",
    "get_female_any(df_auths_compare)\n",
    "print()\n",
    "print(\"Control group:\")\n",
    "get_female_any(df_auths_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "189bfed9-a9e7-46bd-9a4d-4abeb9f7a216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare group:\n",
      "Female first author: 401  /  0.2812061711079944\n",
      "Male first author  : 1025   /  0.7187938288920056\n",
      "Total:  1426\n",
      "\n",
      "Control group:\n",
      "Female first author: 564  /  0.30938014262205155\n",
      "Male first author  : 1259   /  0.6906198573779484\n",
      "Total:  1823\n"
     ]
    }
   ],
   "source": [
    "def get_female_first(df_pubs):\n",
    "    female_first = df_pubs[\"female_first\"].value_counts()[1]\n",
    "    male_first = df_pubs[\"female_first\"].value_counts()[0]\n",
    "    total = female_first + male_first\n",
    "\n",
    "    print(f\"Female first author: {female_first}  /  {female_first / total}\")\n",
    "    print(f\"Male first author  : {male_first}   /  {male_first / total}\")\n",
    "    print(f\"Total:  {total}\")\n",
    "\n",
    "\n",
    "print(\"Compare group:\")\n",
    "get_female_first(df_pubs_compare)\n",
    "print()\n",
    "print(\"Control group:\")\n",
    "get_female_first(df_pubs_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c516b30-c32b-4f22-9b53-1e04189da970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare group:\n",
      "Female last author: 336  /  0.23562412342215988\n",
      "Male last author  : 1090   /  0.7643758765778401\n",
      "Total:  1426\n",
      "\n",
      "Control group:\n",
      "Female last author: 395  /  0.21667580910586945\n",
      "Male last author  : 1428   /  0.7833241908941305\n",
      "Total:  1823\n"
     ]
    }
   ],
   "source": [
    "def get_female_last(df_pubs):\n",
    "    female_last = df_pubs[\"female_last\"].value_counts()[1]\n",
    "    male_last = df_pubs[\"female_last\"].value_counts()[0]\n",
    "    total = female_last + male_last\n",
    "\n",
    "    print(f\"Female last author: {female_last}  /  {female_last / total}\")\n",
    "    print(f\"Male last author  : {male_last}   /  {male_last / total}\")\n",
    "    print(f\"Total:  {total}\")\n",
    "\n",
    "\n",
    "print(\"Compare group:\")\n",
    "get_female_last(df_pubs_compare)\n",
    "print()\n",
    "print(\"Control group:\")\n",
    "get_female_last(df_pubs_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc25536c-97ba-4705-a20e-f5c33e37a170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test: female any Ttest_indResult(statistic=-0.7263278762737502, pvalue=0.7661549263237635)\n",
      "t-test: female first Ttest_indResult(statistic=-1.7443514853693605, pvalue=0.959403780265583)\n",
      "t-test: female last Ttest_indResult(statistic=1.2834779402615775, pvalue=0.09970813645867084)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "def get_female_any(df):\n",
    "    return df.groupby(\"pub_id\").gender_ints.any()\n",
    "\n",
    "\n",
    "def get_without_na(df):\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"t-test: female any {ttest_ind(get_female_any(df_auths_compare), get_female_any(df_auths_control), nan_policy='omit', alternative='greater')}\"\n",
    ")\n",
    "print(\n",
    "    f\"t-test: female first {ttest_ind(df_pubs_compare.female_first.dropna(), df_pubs_control.female_first.dropna(), alternative='greater')}\"\n",
    ")\n",
    "print(\n",
    "    f\"t-test: female last {ttest_ind(df_pubs_compare.female_last.dropna(), df_pubs_control.female_last.dropna(), nan_policy='omit', alternative='greater')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7c442-8cd2-471d-9edb-32eeef248ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
